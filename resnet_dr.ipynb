{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weYTOC539qI4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hAidEsD96H1",
        "outputId": "e49c9a76-0f3a-45a9-d629-c91729dad802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm2WEh299qI7",
        "outputId": "85c0ec5b-2687-462e-a4d5-e370051d51b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms as tsf\n",
        "import csv\n",
        "%pylab inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgA-mw69qI8"
      },
      "source": [
        "BAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1EqZQHs9qI9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "class ChannelGate(nn.Module):\n",
        "    def __init__(self, gate_channel, reduction_ratio=16, num_layers=1):\n",
        "        super(ChannelGate, self).__init__()\n",
        "        #self.gate_activation = gate_activation\n",
        "        self.gate_c = nn.Sequential()\n",
        "        self.gate_c.add_module( 'flatten', Flatten() )\n",
        "        gate_channels = [gate_channel]\n",
        "        gate_channels += [gate_channel // reduction_ratio] * num_layers\n",
        "        gate_channels += [gate_channel]\n",
        "        for i in range( len(gate_channels) - 2 ):\n",
        "            self.gate_c.add_module( 'gate_c_fc_%d'%i, nn.Linear(gate_channels[i], gate_channels[i+1]) )\n",
        "            self.gate_c.add_module( 'gate_c_bn_%d'%(i+1), nn.BatchNorm1d(gate_channels[i+1]) )\n",
        "            self.gate_c.add_module( 'gate_c_relu_%d'%(i+1), nn.ReLU() )\n",
        "        self.gate_c.add_module( 'gate_c_fc_final', nn.Linear(gate_channels[-2], gate_channels[-1]) )\n",
        "    def forward(self, in_tensor):\n",
        "        avg_pool = F.avg_pool2d( in_tensor, in_tensor.size(2), stride=in_tensor.size(2) )\n",
        "        return self.gate_c( avg_pool ).unsqueeze(2).unsqueeze(3).expand_as(in_tensor)\n",
        "\n",
        "class SpatialGate(nn.Module):\n",
        "    def __init__(self, gate_channel, reduction_ratio=16, dilation_conv_num=2, dilation_val=4):\n",
        "        super(SpatialGate, self).__init__()\n",
        "        self.gate_s = nn.Sequential()\n",
        "        self.gate_s.add_module( 'gate_s_conv_reduce0', nn.Conv2d(gate_channel, gate_channel//reduction_ratio, kernel_size=1))\n",
        "        self.gate_s.add_module( 'gate_s_bn_reduce0',\tnn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
        "        self.gate_s.add_module( 'gate_s_relu_reduce0',nn.ReLU() )\n",
        "        for i in range( dilation_conv_num ):\n",
        "            self.gate_s.add_module( 'gate_s_conv_di_%d'%i, nn.Conv2d(gate_channel//reduction_ratio, gate_channel//reduction_ratio, kernel_size=3, \\\n",
        "\t\t\t\t\t\tpadding=dilation_val, dilation=dilation_val) )\n",
        "            self.gate_s.add_module( 'gate_s_bn_di_%d'%i, nn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
        "            self.gate_s.add_module( 'gate_s_relu_di_%d'%i, nn.ReLU() )\n",
        "        self.gate_s.add_module( 'gate_s_conv_final', nn.Conv2d(gate_channel//reduction_ratio, 1, kernel_size=1) )\n",
        "    def forward(self, in_tensor):\n",
        "        return self.gate_s( in_tensor ).expand_as(in_tensor)\n",
        "class BAM(nn.Module):\n",
        "    def __init__(self, gate_channel):\n",
        "        super(BAM, self).__init__()\n",
        "        self.channel_att = ChannelGate(gate_channel)\n",
        "        self.spatial_att = SpatialGate(gate_channel)\n",
        "    def forward(self,in_tensor):\n",
        "        att = 1 + F.sigmoid( self.channel_att(in_tensor) * self.spatial_att(in_tensor) )\n",
        "        return att * in_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kRVbxND9qI-"
      },
      "source": [
        "CBAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaFiW3J99qI_"
      },
      "outputs": [],
      "source": [
        "class BasicConv(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
        "        super(BasicConv, self).__init__()\n",
        "        self.out_channels = out_planes\n",
        "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
        "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
        "        self.relu = nn.ReLU() if relu else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.bn is not None:\n",
        "            x = self.bn(x)\n",
        "        if self.relu is not None:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class CFlatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "class CChannelGate(nn.Module):\n",
        "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
        "        super(CChannelGate, self).__init__()\n",
        "        self.gate_channels = gate_channels\n",
        "        self.mlp = nn.Sequential(\n",
        "            Flatten(),\n",
        "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
        "            )\n",
        "        self.pool_types = pool_types\n",
        "    def forward(self, x):\n",
        "        channel_att_sum = None\n",
        "        for pool_type in self.pool_types:\n",
        "            if pool_type=='avg':\n",
        "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
        "                channel_att_raw = self.mlp( avg_pool )\n",
        "            elif pool_type=='max':\n",
        "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
        "                channel_att_raw = self.mlp( max_pool )\n",
        "            elif pool_type=='lp':\n",
        "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
        "                channel_att_raw = self.mlp( lp_pool )\n",
        "            elif pool_type=='lse':\n",
        "                # LSE pool only\n",
        "                lse_pool = logsumexp_2d(x)\n",
        "                channel_att_raw = self.mlp( lse_pool )\n",
        "\n",
        "            if channel_att_sum is None:\n",
        "                channel_att_sum = channel_att_raw\n",
        "            else:\n",
        "                channel_att_sum = channel_att_sum + channel_att_raw\n",
        "\n",
        "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
        "        return x * scale\n",
        "\n",
        "def logsumexp_2d(tensor):\n",
        "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
        "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
        "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
        "    return outputs\n",
        "\n",
        "class ChannelPool(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
        "\n",
        "class CSpatialGate(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CSpatialGate, self).__init__()\n",
        "        kernel_size = 7\n",
        "        self.compress = ChannelPool()\n",
        "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
        "    def forward(self, x):\n",
        "        x_compress = self.compress(x)\n",
        "        x_out = self.spatial(x_compress)\n",
        "        scale = F.sigmoid(x_out) # broadcasting\n",
        "        return x * scale\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.CChannelGate = CChannelGate(gate_channels, reduction_ratio, pool_types)\n",
        "        self.no_spatial=no_spatial\n",
        "        if not no_spatial:\n",
        "            self.CSpatialGate = CSpatialGate()\n",
        "    def forward(self, x):\n",
        "        x_out = self.CChannelGate(x)\n",
        "        if not self.no_spatial:\n",
        "            x_out = self.CSpatialGate(x_out)\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GUyNUpX9qJA"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def csv_reader(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        breast = list(csv.reader(f))\n",
        "    return breast\n",
        "def get_datas(image_dir,suffix=\".png\"):\n",
        "   \n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    train=csv_reader(\"aptos2019-blindness-detection/train.csv\")\n",
        "    for i in train[1:]:\n",
        "        #y_this=[0.0,0.0,0.0,0.0,0.0]\n",
        "        #y_this[int(i[1])]=1.0\n",
        "        image_paths.append(image_dir+'/'+i[0]+'.png')\n",
        "        labels.append(int(i[1]))\n",
        "        \n",
        "    return image_paths,labels\n",
        "\n",
        "def show_batch(img_paths):\n",
        "    '''\n",
        "   \n",
        "    '''\n",
        "    randomed = []\n",
        "\n",
        "    if len(img_paths) <= 25:\n",
        "        randomed = list(range(0, len(img_paths)))\n",
        "    else:\n",
        "        for i in range(0, len(img_paths)):\n",
        "            random = np.random.randint(0, len(img_paths))\n",
        "            if random not in randomed:\n",
        "                randomed.append(random)\n",
        "            if len(randomed) == 25:\n",
        "                break\n",
        "    \n",
        "    plt.figure(dpi=224)\n",
        "    for i in range(len(randomed)):\n",
        "        img = Image.open(img_paths[randomed[i]])\n",
        "        plt.subplot(5, 5, i+1) \n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_mRDC1-IXx",
        "outputId": "2110d9e0-7eb0-4ddd-eb8f-dad723367f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ],
      "source": [
        "cd drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9_Ym1Vg-b0M",
        "outputId": "5085c87b-e444-4b88-c48e-26d3633d3dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbueFuSy-jUi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT3a9pik9qJA"
      },
      "outputs": [],
      "source": [
        "img_dir = os.path.abspath('aptos2019-blindness-detection/train_images')\n",
        "shuffix = \".png\"\n",
        "img_paths, labels = get_datas(img_dir, suffix=shuffix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivOS1kXh9qJB"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        if use_cbam:\n",
        "            self.cbam = CBAM( planes, 16 )\n",
        "        else:\n",
        "            self.cbam = None\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        if not self.cbam is None:\n",
        "            out = self.cbam(out)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_cbam=False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        if use_cbam:\n",
        "            self.cbam = CBAM( planes * 4, 16 )\n",
        "        else:\n",
        "            self.cbam = None\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        if not self.cbam is None:\n",
        "            out = self.cbam(out)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, att_type=None):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        if att_type=='BAM':\n",
        "            self.bam1 = BAM(64*block.expansion)\n",
        "            self.bam2 = BAM(128*block.expansion)\n",
        "            self.bam3 = BAM(256*block.expansion)\n",
        "        else:\n",
        "            self.bam1, self.bam2, self.bam3 = None, None, None\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], att_type=att_type)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_type=att_type)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_type=att_type)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, att_type=att_type)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, 1000)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1,att_type=None):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, use_cbam=att_type=='CBAM'))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, use_cbam=att_type=='CBAM'))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        if not self.bam1 is None:\n",
        "            x = self.bam1(x)\n",
        "        x = self.layer2(x)\n",
        "        if not self.bam2 is None:\n",
        "            x = self.bam2(x)\n",
        "        x = self.layer3(x)\n",
        "        if not self.bam3 is None:\n",
        "            x = self.bam3(x)\n",
        "        feat = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(feat)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return feat, x\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, att_type=None):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [2, 2, 2, 2], att_type=att_type)\n",
        "    if pretrained:\n",
        "        save_model = model_zoo.load_url(model_urls['resnet18'])\n",
        "        model_dict =  model.state_dict()\n",
        "        state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
        "        model_dict.update(state_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=False, att_type=None):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3], att_type=att_type)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, att_type=None):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 4, 23, 3], att_type=att_type)\n",
        "    if pretrained:\n",
        "        save_model = model_zoo.load_url(model_urls['resnet101'])\n",
        "        model_dict =  model.state_dict()\n",
        "        state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
        "        model_dict.update(state_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=False, att_type=None):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], att_type=att_type)\n",
        "    if pretrained:\n",
        "        save_model = model_zoo.load_url(model_urls['resnet152'])\n",
        "        model_dict =  model.state_dict()\n",
        "        state_dict = {k:v for k,v in save_model.items() if k in model_dict.keys()}\n",
        "        model_dict.update(state_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TILkGsEZ9qJD"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class EyeDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, gray=False, transform=None):\n",
        "        super(EyeDataset, self).__init__()\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.gray = gray\n",
        "        self.transform = transform\n",
        "        self.length = len(img_paths)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_paths[index]\n",
        "        label = self.labels[index]\n",
        "        img = Image.open(img_path)\n",
        "        if self.gray:\n",
        "            img.convert(\"L\")\n",
        "        else:\n",
        "            img.convert(\"RGB\")\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        \n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB8BIWsW9qJF"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(img_paths, labels, test_size=0.3, random_state=0, stratify=labels)\n",
        "\n",
        "img_size = 224\n",
        "train_transform = tsf.Compose([\n",
        "    tsf.Resize((img_size, img_size)),\n",
        "    tsf.RandomHorizontalFlip(),\n",
        "    tsf.RandomVerticalFlip(),\n",
        "    tsf.ToTensor(),\n",
        "    tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25])\n",
        "])\n",
        "val_transform = tsf.Compose([\n",
        "    tsf.Resize((img_size, img_size)),\n",
        "    tsf.ToTensor(),\n",
        "    tsf.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25])\n",
        "])\n",
        "train_dataset =EyeDataset(train_paths, torch.tensor(train_labels), transform=train_transform)\n",
        "val_dataset = EyeDataset(val_paths, torch.tensor(val_labels), transform=val_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaxBZk5C9qJF",
        "outputId": "a57f05d2-aba8-4a40-f095-0aafc1feeb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from torch.utils.data import DataLoader\n",
        "wights=[]\n",
        "train_time=[1,5,2,9,6]\n",
        "for i in train_labels:\n",
        "    wights.append(train_time[int(i)])\n",
        "sampler = WeightedRandomSampler(wights, len(wights),replacement=True)\n",
        "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=8, num_workers=4, sampler=sampler) #备注：在windows系统中多线程可能存在问题，所以设置num_workers为0\n",
        "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=1, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUKI526N9qJF"
      },
      "outputs": [],
      "source": [
        "def train_for(x,label,opt,model,losses,total,number,count):\n",
        "    for _ in range(number):\n",
        "        x = x.to(device, dtype=torch.float32)\n",
        "        label = label.to(device, dtype=torch.long)\n",
        "        batch = x.size(0)\n",
        "        total += batch\n",
        "        opt.zero_grad()\n",
        "        _,pred = model(x)\n",
        "        loss = criterion(pred, label)\n",
        "        loss.backward()\n",
        "        pred = torch.max(pred, dim=1)[1]\n",
        "        for i in range(len(pred)):\n",
        "            if int(pred[i])==int(label[i]):\n",
        "                count+=1\n",
        "        if total%128==0:\n",
        "            print(loss)\n",
        "            print(total)\n",
        "            print(\"acc: \"+str(count/128))\n",
        "            count=0\n",
        "        opt.step() \n",
        "        losses += loss.item() * batch\n",
        "    return opt,model,losses,total,count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "066567f2e7774368b5a5272196fe0102",
            "a1715db029dd46289b0ac2d7cfc3437c",
            "c301d3a145004970b11ef63299fde936",
            "88dd8987684d45478311e073b17e923f",
            "6a518b1246ce491fb74bf7ee56e5ca0b",
            "81c743874dac4a23aaeb1e332d7d9f65",
            "8748cc0a966e4423b71b2e5a394428a7",
            "565a0614b558465c9053cbe194a52334",
            "f6d9a5ce33ba42518ed55a955f522e5d",
            "7964d4bd923e430b90af578f0810d774",
            "58119c2196a34305acf045b36d6810a4"
          ]
        },
        "id": "5exn4kKK9qJG",
        "outputId": "ce8c1a29-1edf-4578-ebe7-09d3a388781f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "066567f2e7774368b5a5272196fe0102",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/170M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4679, grad_fn=<NllLossBackward0>)\n",
            "128\n",
            "acc: 0.328125\n",
            "tensor(0.9902, grad_fn=<NllLossBackward0>)\n",
            "256\n",
            "acc: 0.421875\n",
            "tensor(1.9568, grad_fn=<NllLossBackward0>)\n",
            "384\n",
            "acc: 0.4140625\n",
            "tensor(1.5069, grad_fn=<NllLossBackward0>)\n",
            "512\n",
            "acc: 0.4921875\n",
            "tensor(1.4375, grad_fn=<NllLossBackward0>)\n",
            "640\n",
            "acc: 0.4765625\n",
            "tensor(1.5314, grad_fn=<NllLossBackward0>)\n",
            "768\n",
            "acc: 0.46875\n",
            "tensor(1.2268, grad_fn=<NllLossBackward0>)\n",
            "896\n",
            "acc: 0.4609375\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "model = resnet101(pretrained=True,att_type='BAM')\n",
        "#model=DenseNet121()\n",
        "model.fc= nn.Linear(2048, 5)\n",
        "opt = torch.optim.SGD(model.parameters(),lr=0.004, momentum=0.9, nesterov=True)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size = 6, gamma = 0.1, last_epoch=-1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "for __ in range(1):\n",
        "    for epoch in range(1):\n",
        "        losses = 0.0\n",
        "        total = 0\n",
        "        count=0\n",
        "        corrects = 0\n",
        "        model.train()\n",
        "        for x, label in train_loader:\n",
        "            opt,model,losses,total,count=train_for(x,label,opt,model,losses,total,1,count)\n",
        "        print(\"avg loss: \"+str(losses))\n",
        "        scheduler.step()\n",
        "torch.save(model,\"./model.pkl\")\n",
        "torch.save(model.state_dict(),\"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "fktt1Rd29qJG",
        "outputId": "9995f489-80d3-4dee-d914-1321e4f7d867"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a0c10b10652b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    losses = 0.0\n",
        "    total = 0\n",
        "    corrects = 0\n",
        "    tbie=[0,0,0,0,0]\n",
        "    bie=[0,0,0,0,0]\n",
        "    pre=[0,0,0,0,0]\n",
        "    alls=[[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]]\n",
        "    count=0\n",
        "    for x, label in val_loader:\n",
        "        x = x.to(device, dtype=torch.float32)          \n",
        "        label = label.to(device, dtype=torch.long)\n",
        "        batch = x.size(0)\n",
        "        total += batch\n",
        "        _,pred = model(x)\n",
        "        loss = criterion(pred, label)\n",
        "        losses += loss.item() * batch\n",
        "        pred = torch.max(pred, dim=1)[1]\n",
        "        for i in range(len(pred)):\n",
        "            if int(pred[i])==int(label[i]):\n",
        "                count+=1\n",
        "        if total%128==0:\n",
        "            print(loss)\n",
        "            print(total)\n",
        "            print(\"acc: \"+str(count))\n",
        "            count=0\n",
        "        for i in range(len(pred)):\n",
        "            cc=pred[i]\n",
        "            cd=label[i]\n",
        "            tbie[int(cd)]+=1\n",
        "            alls[cc][cd]+=1\n",
        "            if int(cc)==int(cd):\n",
        "                corrects=corrects+1\n",
        "                bie[int(cc)]+=1\n",
        "    print(\"correct: \"+str(corrects/total))\n",
        "    for z in range(5):\n",
        "        print(\"class \"+str(z)+\" correct \"+str(bie[z]/tbie[z]))\n",
        "        print(\"which are \"+str(alls[z]))\n",
        "    print(bie)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "h0xU4NhQ9qJG",
        "outputId": "ee73d92b-303d-4c73-de41-569e5af459be"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3b440e47b969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "test_dir = os.path.abspath('aptos2019-blindness-detection/test_images')\n",
        "test_paths = glob.glob(os.path.join(test_dir, \"*.png\"))\n",
        "filenames = []\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for path in test_paths:\n",
        "        filename = os.path.basename(path)\n",
        "        filenames.append(filename)\n",
        "        img = Image.open(path)\n",
        "        img = val_transform(img)\n",
        "        img=img.unsqueeze(0)\n",
        "        img = img.to(device)\n",
        "        _,pred = model(img)\n",
        "        pred = torch.max(pred, dim=1)[1]\n",
        "        preds.append(int(pred))\n",
        "\n",
        "output_dict = {\n",
        "    \"filename\":filenames,\n",
        "    \"pred\":preds\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "output = pd.DataFrame(output_dict)\n",
        "output.to_csv(\"./submission.csv\", index=False, encoding=\"utf-8\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "resnet-dr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "066567f2e7774368b5a5272196fe0102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1715db029dd46289b0ac2d7cfc3437c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c301d3a145004970b11ef63299fde936",
              "IPY_MODEL_88dd8987684d45478311e073b17e923f",
              "IPY_MODEL_6a518b1246ce491fb74bf7ee56e5ca0b"
            ]
          }
        },
        "a1715db029dd46289b0ac2d7cfc3437c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c301d3a145004970b11ef63299fde936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81c743874dac4a23aaeb1e332d7d9f65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8748cc0a966e4423b71b2e5a394428a7"
          }
        },
        "88dd8987684d45478311e073b17e923f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_565a0614b558465c9053cbe194a52334",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 178728960,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 178728960,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6d9a5ce33ba42518ed55a955f522e5d"
          }
        },
        "6a518b1246ce491fb74bf7ee56e5ca0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7964d4bd923e430b90af578f0810d774",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170M/170M [00:01&lt;00:00, 95.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58119c2196a34305acf045b36d6810a4"
          }
        },
        "81c743874dac4a23aaeb1e332d7d9f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8748cc0a966e4423b71b2e5a394428a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "565a0614b558465c9053cbe194a52334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6d9a5ce33ba42518ed55a955f522e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7964d4bd923e430b90af578f0810d774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58119c2196a34305acf045b36d6810a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}